{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa2b979",
   "metadata": {},
   "source": [
    "# Prédiction d'énergie moléculaire avec Transformer\n",
    "\n",
    "Ce notebook implémente une approche plus sophistiquée utilisant un Transformer pour prédire l'énergie des molécules. Cette approche :\n",
    "1. Traite chaque atome comme un token avec ses caractéristiques propres\n",
    "2. Utilise l'attention pour capturer les interactions entre atomes\n",
    "3. Intègre la géométrie 3D dans le modèle\n",
    "4. Utilise une architecture plus profonde pour plus de capacité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e16149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import os\n",
    "from ase.io import read\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration de PyTorch\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fec872b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolecularTransformerDataset(Dataset):\n",
    "    def __init__(self, molecule_ids, energies=None, max_atoms=23, root_dir='../data/atoms/train/'):\n",
    "        self.molecule_ids = molecule_ids\n",
    "        self.energies = energies\n",
    "        self.max_atoms = max_atoms\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.molecule_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        mol_id = self.molecule_ids[idx]\n",
    "        xyz_path = os.path.join(self.root_dir, f'id_{mol_id}.xyz')\n",
    "        atoms = read(xyz_path)\n",
    "        \n",
    "        # Récupérer les positions et numéros atomiques\n",
    "        positions = atoms.get_positions()\n",
    "        atomic_numbers = atoms.get_atomic_numbers()\n",
    "        n_atoms = len(positions)\n",
    "        \n",
    "        # Préparer les entrées du transformer\n",
    "        atom_features = np.zeros((self.max_atoms, 4))  # [x, y, z, atomic_number]\n",
    "        mask = np.zeros(self.max_atoms, dtype=bool)\n",
    "        \n",
    "        # Remplir avec les données réelles\n",
    "        atom_features[:n_atoms, :3] = positions\n",
    "        atom_features[:n_atoms, 3] = atomic_numbers\n",
    "        mask[:n_atoms] = 1\n",
    "        \n",
    "        output = {\n",
    "            'features': torch.FloatTensor(atom_features),\n",
    "            'mask': torch.BoolTensor(mask),\n",
    "            'n_atoms': n_atoms\n",
    "        }\n",
    "        \n",
    "        if self.energies is not None:\n",
    "            output['energy'] = torch.FloatTensor([self.energies[idx]])\n",
    "            \n",
    "        return output\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % num_heads == 0\n",
    "        \n",
    "        self.d_k = d_model // num_heads\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def attention(self, q, k, v, mask=None, dropout=None):\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "            scores = scores.masked_fill(~mask, float('-inf'))\n",
    "        scores = F.softmax(scores, dim=-1)\n",
    "        if dropout is not None:\n",
    "            scores = dropout(scores)\n",
    "        output = torch.matmul(scores, v)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        bs = q.size(0)\n",
    "        \n",
    "        # Linear projections and split into heads\n",
    "        k = self.k_linear(k).view(bs, -1, self.num_heads, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.num_heads, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.num_heads, self.d_k)\n",
    "        \n",
    "        # Transpose to get dimensions [batch, head, seq_length, d_k]\n",
    "        k = k.transpose(1, 2)\n",
    "        q = q.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "        \n",
    "        # Apply attention\n",
    "        scores = self.attention(q, k, v, mask)\n",
    "        \n",
    "        # Concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        attention_out = self.attention(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attention_out))\n",
    "        ff_out = self.ff(x)\n",
    "        x = self.norm2(x + self.dropout(ff_out))\n",
    "        return x\n",
    "\n",
    "class MolecularTransformer(nn.Module):\n",
    "    def __init__(self, d_model=256, num_heads=8, num_layers=6, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding des caractéristiques atomiques\n",
    "        self.feature_embedding = nn.Sequential(\n",
    "            nn.Linear(4, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Couches Transformer\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, num_heads, d_model * 4, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Couches de sortie\n",
    "        self.output_layers = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, d_model // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 4, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, mask=None):\n",
    "        # Embedding des caractéristiques\n",
    "        x = self.feature_embedding(features)\n",
    "        \n",
    "        # Application des couches Transformer\n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x, mask)\n",
    "            \n",
    "        # Global pooling avec masque\n",
    "        if mask is not None:\n",
    "            x = x * mask.unsqueeze(-1)\n",
    "            x = x.sum(dim=1) / mask.sum(dim=1, keepdim=True)\n",
    "        else:\n",
    "            x = x.mean(dim=1)\n",
    "            \n",
    "        # Prédiction finale\n",
    "        return self.output_layers(x).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4b23c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement sur cuda\n",
      "Nombre total de paramètres: 606,081\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données\n",
    "train_energies = pd.read_csv('../data/energies/train.csv')\n",
    "molecule_ids = train_energies['id'].values\n",
    "energies = train_energies['energy'].values\n",
    "\n",
    "# Séparation train/validation\n",
    "train_ids, val_ids, y_train, y_val = train_test_split(\n",
    "    molecule_ids, energies, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Création des datasets\n",
    "train_dataset = MolecularTransformerDataset(train_ids, y_train)\n",
    "val_dataset = MolecularTransformerDataset(val_ids, y_val)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# Configuration du modèle\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MolecularTransformer(\n",
    "    d_model=128,  # Réduit de 256 à 128\n",
    "    num_heads=4,  # Réduit de 8 à 4\n",
    "    num_layers=3,  # Réduit de 6 à 3\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "# Optimiseur et fonction de perte avec un learning rate légèrement plus élevé\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Afficher la taille du modèle et le device\n",
    "print(f\"Entraînement sur {device}\")\n",
    "print(f\"Nombre total de paramètres: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e3adfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début de l'entraînement...\n",
      "Époque [10/200]\n",
      "Perte entraînement: 94.8289\n",
      "Perte validation: 21.5313\n",
      "RMSE validation: 4.6395\n",
      "MAE validation: 3.6669\n",
      "--------------------\n",
      "Époque [10/200]\n",
      "Perte entraînement: 94.8289\n",
      "Perte validation: 21.5313\n",
      "RMSE validation: 4.6395\n",
      "MAE validation: 3.6669\n",
      "--------------------\n",
      "Époque [20/200]\n",
      "Perte entraînement: 85.5589\n",
      "Perte validation: 24.1312\n",
      "RMSE validation: 4.9117\n",
      "MAE validation: 3.8207\n",
      "--------------------\n",
      "Époque [20/200]\n",
      "Perte entraînement: 85.5589\n",
      "Perte validation: 24.1312\n",
      "RMSE validation: 4.9117\n",
      "MAE validation: 3.8207\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 53\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     val_predictions, val_true, val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, criterion, device)\n\u001b[1;32m     56\u001b[0m     history\u001b[38;5;241m.\u001b[39mappend((train_loss, val_loss))\n",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorboard/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorboard/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorboard/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m, in \u001b[0;36mMolecularTransformerDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m mol_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmolecule_ids[idx]\n\u001b[1;32m     13\u001b[0m xyz_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmol_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.xyz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m atoms \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Récupérer les positions et numéros atomiques\u001b[39;00m\n\u001b[1;32m     17\u001b[0m positions \u001b[38;5;241m=\u001b[39m atoms\u001b[38;5;241m.\u001b[39mget_positions()\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorboard/lib/python3.12/site-packages/ase/io/formats.py:815\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, index, format, parallel, do_not_split_by_at_sign, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_iread(filename, index, \u001b[38;5;28mformat\u001b[39m, io, parallel\u001b[38;5;241m=\u001b[39mparallel,\n\u001b[1;32m    813\u001b[0m                        \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_iread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorboard/lib/python3.12/site-packages/ase/parallel.py:305\u001b[0m, in \u001b[0;36mparallel_generator.<locals>.new_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(generator)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_generator\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (world\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    302\u001b[0m         args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserial\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparallel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)):\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;66;03m# Disable:\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorboard/lib/python3.12/site-packages/ase/io/formats.py:881\u001b[0m, in \u001b[0;36m_iread\u001b[0;34m(filename, index, format, io, parallel, full_output, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# Make sure fd is closed in case loop doesn't finish:\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 881\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdct\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdct\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43matoms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdct\u001b[49m\u001b[43m}\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorboard/lib/python3.12/site-packages/ase/io/formats.py:639\u001b[0m, in \u001b[0;36mwrap_read_function\u001b[0;34m(read, filename, index, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m read(filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m read(filename, index, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorboard/lib/python3.12/site-packages/ase/io/extxyz.py:734\u001b[0m, in \u001b[0;36mread_xyz\u001b[0;34m(fileobj, index, properties_parser)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;66;03m# check for consistency with frame index table\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mint\u001b[39m(fileobj\u001b[38;5;241m.\u001b[39mreadline()) \u001b[38;5;241m==\u001b[39m natoms\n\u001b[0;32m--> 734\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_read_xyz_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnatoms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperties_parser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnvec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorboard/lib/python3.12/site-packages/ase/io/extxyz.py:484\u001b[0m, in \u001b[0;36m_read_xyz_frame\u001b[0;34m(lines, natoms, properties_parser, nvec)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m symbols \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    482\u001b[0m     symbols \u001b[38;5;241m=\u001b[39m [s\u001b[38;5;241m.\u001b[39mcapitalize() \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m symbols]\n\u001b[0;32m--> 484\u001b[0m atoms \u001b[38;5;241m=\u001b[39m \u001b[43mAtoms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumbers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnumbers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m              \u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpositions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcharges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minitial_charges\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m              \u001b[49m\u001b[43mpbc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m              \u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# Read and set constraints\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmove_mask\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arrays:\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorboard/lib/python3.12/site-packages/ase/atoms.py:226\u001b[0m, in \u001b[0;36mAtoms.__init__\u001b[0;34m(self, symbols, positions, numbers, tags, momenta, masses, magmoms, charges, scaled_positions, cell, pbc, celldisp, constraint, calculator, info, velocities)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cell \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     cell \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m--> 226\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m celldisp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     celldisp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorboard/lib/python3.12/site-packages/ase/atoms.py:420\u001b[0m, in \u001b[0;36mAtoms.set_cell\u001b[0;34m(self, cell, scale_atoms, apply_constraint)\u001b[0m\n\u001b[1;32m    417\u001b[0m     M \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msolve(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell\u001b[38;5;241m.\u001b[39mcomplete(), cell\u001b[38;5;241m.\u001b[39mcomplete())\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositions[:] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositions, M)\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcell\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m cell\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorboard/lib/python3.12/site-packages/ase/cell.py:232\u001b[0m, in \u001b[0;36mCell.__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return an array with the three angles alpha, beta, and gamma.\"\"\"\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcellpar()[\u001b[38;5;241m3\u001b[39m:]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fonction d'entraînement\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        features = batch['features'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        target_energies = batch['energy'].to(device).squeeze(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features, mask)\n",
    "        loss = criterion(outputs, target_energies)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Fonction d'évaluation\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_energies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            features = batch['features'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            target_energies = batch['energy'].to(device).squeeze(-1)\n",
    "            \n",
    "            outputs = model(features, mask)\n",
    "            loss = criterion(outputs, target_energies)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            true_energies.extend(target_energies.cpu().numpy())\n",
    "            \n",
    "    return np.array(predictions), np.array(true_energies), total_loss / len(loader)\n",
    "\n",
    "# Entraînement\n",
    "num_epochs = 200\n",
    "best_val_loss = float('inf')\n",
    "patience = 15\n",
    "patience_counter = 0\n",
    "history = []\n",
    "\n",
    "print(\"Début de l'entraînement...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_predictions, val_true, val_loss = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    history.append((train_loss, val_loss))\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        best_model = model.state_dict()\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping à l'époque {epoch+1}\")\n",
    "        break\n",
    "        \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        rmse = np.sqrt(mean_squared_error(val_true, val_predictions))\n",
    "        mae = mean_absolute_error(val_true, val_predictions)\n",
    "        print(f\"Époque [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\"Perte entraînement: {train_loss:.4f}\")\n",
    "        print(f\"Perte validation: {val_loss:.4f}\")\n",
    "        print(f\"RMSE validation: {rmse:.4f}\")\n",
    "        print(f\"MAE validation: {mae:.4f}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTemps d'entraînement total: {total_time/60:.2f} minutes\")\n",
    "\n",
    "# Charger le meilleur modèle\n",
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d910429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'évolution de l'entraînement\n",
    "train_losses, val_losses = zip(*history)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Entraînement')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Perte (MSE)')\n",
    "plt.title('Évolution de la perte pendant l\\'entraînement')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Évaluation finale sur l'ensemble de validation\n",
    "val_predictions = evaluate(model, val_loader, criterion, device)\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, val_predictions))\n",
    "val_mae = mean_absolute_error(y_val, val_predictions)\n",
    "\n",
    "print(\"\\nPerformances finales sur l'ensemble de validation:\")\n",
    "print(f\"RMSE: {val_rmse:.4f}\")\n",
    "print(f\"MAE: {val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e444f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données de test\n",
    "test_files = sorted(os.listdir('../data/atoms/test'))\n",
    "test_ids = [int(f.split('_')[1].split('.')[0]) for f in test_files]\n",
    "\n",
    "# Créer le dataset de test\n",
    "test_dataset = MolecularTransformerDataset(test_ids, root_dir='../data/atoms/test/')\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "model.eval()\n",
    "test_predictions, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "# Sauvegarder les prédictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'energy': test_predictions\n",
    "})\n",
    "predictions_df.to_csv('../data/energies/test_pred_transformer.csv', index=False)\n",
    "print(\"Prédictions sauvegardées dans test_pred_transformer.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cabc7fa",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Cette approche utilise une architecture Transformer pour prédire l'énergie des molécules, avec plusieurs avantages :\n",
    "\n",
    "1. Prise en compte explicite des relations entre atomes grâce au mécanisme d'attention\n",
    "2. Traitement naturel de la géométrie 3D\n",
    "3. Capacité à gérer des molécules de tailles différentes\n",
    "4. Architecture plus profonde permettant de capturer des relations complexes\n",
    "\n",
    "La convergence est plus lente que les approches précédentes, mais le modèle peut potentiellement atteindre de meilleures performances grâce à sa capacité à modéliser des interactions complexes entre les atomes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tensorboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
